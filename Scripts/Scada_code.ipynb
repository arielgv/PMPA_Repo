{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join('..', 'Inputs', 'StationPoints.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "        'NAME': 'Key',\n",
    "        'DESC': 'Name',\n",
    "        'ZONEID': 'pAORGroup',\n",
    "        'ALRMPRIOR': 'Priority'\n",
    "    }\n",
    "df = df.rename(columns=column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "62    0\n",
       "63    0\n",
       "64    0\n",
       "65    0\n",
       "66    3\n",
       "Name: Priority, Length: 67, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Priority']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World from scada_processing!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def scada_processing():\n",
    "    print(\"Hello World from scada_processing!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scada_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 56 (1180869797.py, line 59)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[21], line 59\u001b[0;36m\u001b[0m\n\u001b[0;31m    def process_status_points(df_station):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 56\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def scada_processing():\n",
    "    print(\"Hello World from scada_processing!\")\n",
    "    \n",
    "    # Procesar StationPoints.CSV\n",
    "    df_station = process_station_points()\n",
    "    if df_station is not None:\n",
    "        generate_station_dat(df_station)\n",
    "    \n",
    "    # Procesar AnalogPoints.csv\n",
    "    df_analog = process_analog_points()\n",
    "    if df_analog is not None:\n",
    "        print(\"\\nPrimeras filas del DataFrame de puntos analógicos:\")\n",
    "        print(df_analog.head())\n",
    "        generate_analog_dat(df_analog)\n",
    "    \n",
    "    # Procesar StatusPoints.csv\n",
    "    df_status = process_status_points(df_station)\n",
    "    if df_status is not None:\n",
    "        print(\"\\nPrimeras filas del DataFrame de puntos de estado:\")\n",
    "        print(df_status.head())\n",
    "        # Aquí puedes añadir una función para generar el archivo .dat de status si es necesario\n",
    "\n",
    "def process_station_points():\n",
    "    csv_path = os.path.join('..', 'Inputs', 'StationPoints.CSV')\n",
    "    \n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Error: No se pudo encontrar el archivo en {csv_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Archivo encontrado: {csv_path}\")\n",
    "    df_station = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Asegurarse de que tenemos la columna PKEY\n",
    "    if 'PKEY' not in df_station.columns:\n",
    "        print(\"Error: La columna PKEY no está presente en StationPoints.CSV\")\n",
    "        return None\n",
    "    \n",
    "    column_mapping = {\n",
    "        'NAME': 'Key',\n",
    "        'DESC': 'Name',\n",
    "        'ZONEID': 'pAORGroup',\n",
    "        'ALRMPRIOR': 'Priority'\n",
    "    }\n",
    "    df_station = df_station.rename(columns=column_mapping)\n",
    "    df_station['Order'] = range(1, len(df_station) + 1)\n",
    "    \n",
    "    print(\"\\nPrimeras filas del DataFrame de estaciones:\")\n",
    "    print(df_station.head())\n",
    "    \n",
    "    return df_station\n",
    "\n",
    "def process_analog_points():\n",
    "    # ... (el código existente se mantiene igual)\n",
    "\n",
    "def process_status_points(df_station):\n",
    "    csv_path = os.path.join('..', 'Inputs', 'StatusPoints.csv')\n",
    "    \n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Error: No se pudo encontrar el archivo en {csv_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Archivo encontrado: {csv_path}\")\n",
    "    df_status = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Crear un diccionario de mapeo de NAME a PKEY desde df_station\n",
    "    station_map = dict(zip(df_station['Key'], df_station['PKEY']))\n",
    "    \n",
    "    # Crear el nuevo DataFrame con las columnas especificadas\n",
    "    df_status_new = pd.DataFrame()\n",
    "    df_status_new['Type'] = 1\n",
    "    df_status_new['Name'] = df_status['NAME']\n",
    "    df_status_new['pStation'] = df_status['StationPID'].map(station_map)\n",
    "    df_status_new['pStates'] = df_status['PREFSUFFID']\n",
    "    df_status_new['pALARM_GROUP'] = 1\n",
    "    df_status_new['pConfiguredAORGroup'] = df_status['USERTYPEID']\n",
    "    df_status_new['ConfigNormalState'] = df_status['NORMSTATE']\n",
    "    \n",
    "    return df_status_new\n",
    "\n",
    "def generate_station_dat(df_station):\n",
    "    # ... (el código existente se mantiene igual)\n",
    "\n",
    "def generate_analog_dat(df_analog):\n",
    "    # ... (el código existente se mantiene igual)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scada_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_status_points(df_station):\n",
    "    csv_path = os.path.join('..', 'Inputs', 'StatusPoints.csv')\n",
    "    \n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Error: Could not find the file at {csv_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"File found: {csv_path}\")\n",
    "    df_status = pd.read_csv(csv_path)\n",
    "    \n",
    "    \n",
    "    prefix_suffixes_path = os.path.join('..', 'Inputs', 'PrefixSuffixes.csv')\n",
    "    if not os.path.exists(prefix_suffixes_path):\n",
    "        print(f\"Error: Could not find the file at {prefix_suffixes_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"File found: {prefix_suffixes_path}\")\n",
    "    df_prefix_suffixes = pd.read_csv(prefix_suffixes_path)\n",
    "    \n",
    "    # Needed case-insensitive mapping from Name to PKey in PrefixSuffixes\n",
    "    prefix_suffixes_map = {name.upper(): int(pkey) for name, pkey in zip(df_prefix_suffixes['Name'], df_prefix_suffixes['PKey'])}\n",
    "    \n",
    "    # case-insensitive mapping from Key to PKEY in df_station\n",
    "    station_map = {key.upper(): pkey for key, pkey in zip(df_station['Key'], df_station['PKEY'])}\n",
    "    \n",
    "    df_status_new = pd.DataFrame()\n",
    "    df_status_new['Type'] = 1  #\n",
    "    df_status_new['Name'] = df_status['NAME']\n",
    "    \n",
    "\n",
    "    df_status_new['pStation'] = df_status['STATIONPID'].apply(lambda x: station_map.get(str(x).upper(), 0))\n",
    "    \n",
    "    # Logic for pStates (unchanged)\n",
    "    df_status_new['pStates'] = df_status['PREFSUFFID'].apply(\n",
    "        lambda x: prefix_suffixes_map.get(x.upper(), 0) + 200 if x else 0\n",
    "    )\n",
    "    \n",
    "    df_status_new['pALARM_GROUP'] = 1\n",
    "    df_status_new['pConfiguredAORGroup'] = df_status['USERTYPEID']\n",
    "    df_status_new['ConfigNormalState'] = df_status['NORMSTATE']\n",
    "    \n",
    "    # Create the Key column\n",
    "    def create_key(row, station_counter):\n",
    "        xx = str(row['Type']).zfill(2)  # Use actual Type value, padded to 2 digits\n",
    "        print(f\"Type: {xx}\")\n",
    "        yyy = str(row['pStation']).zfill(3)  # Pad station number to 3 digits\n",
    "        zzz = str(station_counter[row['pStation']]).zfill(3)  # Pad point counter to 3 digits\n",
    "        station_counter[row['pStation']] += 1  # Increment counter for this station\n",
    "        return f\"{xx}{yyy}{zzz}\"  # Return as string\n",
    "\n",
    "    station_counter = {station: 1 for station in df_status_new['pStation'].unique()}  # Initialize counters\n",
    "    df_status_new['Key'] = df_status_new.apply(lambda row: create_key(row, station_counter), axis=1)\n",
    "    \n",
    "    return df_status_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1571202779.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    if not os.path.exists(csv_path):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
